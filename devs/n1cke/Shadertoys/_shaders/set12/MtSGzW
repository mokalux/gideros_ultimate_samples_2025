{"Shader":{"ver":"0.1","info":{"id":"MtSGzW","date":"1427259522","viewed":1769,"name":"Theme from Brazil","username":"NBickford","description":"Specular path tracing, AKA Yet Another Thing Which Really Will Not Run At 120 FPS, AKA Super 16 2: Electric Boogaloo.\nThis started out as a naive path tracer, but soon turned into a pretty neat mini-demo!\nInspired by Fairlight's Feed Me Lies and PHOTON.","likes":15,"published":3,"flags":0,"tags":["raytracing","video","gi","globalillumination","pathtracing","pathtracer","film"],"hasliked":0},"renderpass":[{"inputs":[{"id":3,"src":"\/presets\/tex02.jpg","ctype":"texture","channel":2,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"false","srgb":"false","internal":"byte"}},{"id":29,"src":"\/presets\/vid02.ogv","ctype":"video","channel":1,"sampler":{"filter":"linear","wrap":"clamp","vflip":"false","srgb":"false","internal":"byte"}}],"outputs":[{"id":37,"channel":0}],"code":"\/\/Right! It's 11:11 where I'm at, and I'm going to attempt to program a real-time raytracer.\n\/\/Because, um, it seems like a good idea.\n\/\/UNOPTIMIZED. LEARNING FROM THIS WILL MAKE YOUR CODE REALLY BAD.\n\/\/But it might be cool to look at!\n\n\/\/uses IQ's Distance Functions: http:\/\/iquilezles.org\/www\/articles\/distfunctions\/distfunctions.htm\n\/\/and heavily inspired by Fairlight's PHOTON and Feed Me Lies, which was itself inspired by Bot & Dolly's Box:\n\/\/https:\/\/vimeo.com\/75260457\n\n\/\/OpenGL: z minus is into the screen\nvec3 rotY(vec3 p, float rot){\n    return vec3(p.x*cos(rot)-p.z*sin(rot),p.y,p.x*sin(rot)+p.z*cos(rot));\n}\n\nfloat sdBox( vec3 p, vec3 b )\n{\n  vec3 d = abs(p) - b;\n  return min(max(d.x,max(d.y,d.z)),0.0)+length(max(d,0.0));\n  \/\/return length(max(d,0.0));\n}\n\n\/\/distance, object ID (0=walls, 1=box)\nvec2 df(in vec3 p){\n    \/\/back face:\n    float back=2.0;\n    float w2=1.78;\n    float h2=1.0;\n    float wall=0.1\/2.0;\n    \n    p=vec3(mod(p.x-2.0,4.0)-2.0,mod(p.y-1.1,2.2)-1.1,p.z);\n    \n    float d= max(-sdBox(p-vec3(0.0,0.0,-back*0.5+wall),vec3(w2-wall,h2-wall,back*0.5)),\n                 sdBox(p-vec3(0.0,0.0,-back*0.5),vec3(w2+wall,h2+wall,back*0.5)));\n\n    float v=sdBox(p-vec3(0.0,-0.51069,-1.6),vec3(0.319,0.417,0.319));\n    float id=0.5*sign(d-v)+0.5;\n    d=min(d,v);\n    return vec2(d,id);\n}\n\nvec2 intersect(vec3 co, vec3 ci, float tmin){\n    float t=tmin;\n    float dist=0.0;\n    for(int i=0;i<48;i++){\n        dist=df(co+t*ci).r;\n        if(dist<0.001){ \/\/iq uses something smaller\n            break;\n        }\n        t+=dist;\/\/max(dist,0.002);\n    }\n    return vec2(t,df(co+t*ci).g); \/\/may actually be fast!\n}\n\nvec2 intersectFast(vec3 co, vec3 ci, float tmin, float tmax){\n    float t=tmin;\n    float dist=0.0;\n    float minDist=1000.0;\n    for(int i=0;i<14;i++){\n        dist=df(co+t*ci).r;\n        t+=dist;\n    }\n    return vec2(t,df(co+t*ci).g);\n}\n\n\/\/NOT NORMALIZED\nvec3 calcNormal(in vec3 p){\n    float origin=df(p).r;\n    vec3 eps=vec3(0.001,0.0,0.0);\n    float sc=1.0\/eps.x;\n    return sc*vec3(df(p+eps.xyy).r-origin,\n                df(p+eps.yxy).r-origin,\n                df(p+eps.yyx).r-origin);\n}\n\nvec3 gamma(vec3 col){\n    return pow(clamp(col,0.0,1.0),vec3(0.45));\n}\n\nvec3 degamma(vec3 col){\n    return pow(clamp(col,0.0,1.0),vec3(2.2));\n}\n\nfloat degamma(float col){\n    return pow(clamp(col,0.0,1.0),2.2);\n}\n\nvec2 cubemap(vec3 p, vec3 n){\n    \/\/Maps position, normal-> texture coordinate.\n    \/\/n=1,0,0: just y and z\n    \/\/This isn't a particularly nice way to do things, but it works.\n    n=abs(n);\n    if(n.x>n.y && n.x>n.z){\n        return p.yz;\n    }else if(n.y>n.x && n.y>n.z){\n        return p.xz;\n    }else{\n        return p.xy;\n    }\n}\n\nvec4 cubetex(sampler2D channel, vec3 p, vec3 n){\n    return texture2D(channel,cubemap(p,n));\n}\n\n \n\/\/HAAACK\nvec3 texrot(vec3 dirzp, vec3 n){\n    vec3 tn=abs(n);\n    if(tn.z>tn.x && tn.z>tn.y){\n        return dirzp.xyz*sign(n.z);\n    }else if(tn.y>tn.x && tn.y>tn.z){\n        return dirzp.xzy*sign(n.y);\n    }else{\n        return dirzp.zxy*sign(n.x);\n    }\n}\n\n\/\/Pretend the image's really a depth map, and extract a normal from it.\n\/\/We have a position. Right is +X, down is +Y, up is Z.\n\/\/Erm.\n\/\/We'd need tangent-space coordinates, which.... are those easy to find?\n\/\/Easier method: Make stuff up and hope you can get away with it.\n\/\/Okay. So we have the incoming light ray, the normal, and all sorts of other stuff.\n\/\/Per-wall? If +X, z->x, If +Y, z->y. Okay, that's simple! And then invert things if signs are inverted.\n\/\/The math here is obviously bogus.\nvec3 tex2norm(sampler2D channel, vec2 uv, vec3 n){\n    vec2 e=vec2(0.001,0.0); \/\/obv too much, but oh well\n    float center=degamma(texture2D(channel,uv-e).g);\n    float dx=degamma(texture2D(channel,uv+e).g)-center;\n    float dy=degamma(texture2D(channel,uv+e.yx).g)-center;\n    \/\/normal: n.p=d, so n.(e,0,dx)=0,  n.(0,e,dy)=0 - e*n.x+n.z*dx=0. Since we're normalizing...\n    vec3 tn=normalize(clamp(vec3(-dx\/e.x,-dy\/e.x,1),-1.0,1.0));\n    \/\/maybe a mix helps?\n    tn=normalize(mix(vec3(0,0,1),tn,tn.z));\n    return texrot(tn,n);\n}\n\n\n\/\/Evaluates a simple BRDF. Doesn't account for stuff like reflections. That's for the raytracer.\nfloat calcDirectLighting(vec3 p, vec3 norm){   \n        vec3 lightpos=vec3((iMouse.x\/iResolution.x)-0.5,0.0,0);\n        vec3 lightdir=lightpos-p;\n    float e=5.0;\n        return e*dot(normalize(lightdir),norm)\/(dot(lightdir,lightdir));\n}\n\nvec3 sampleMovie(vec2 p){\n    p=vec2(mod(p.x-2.0,4.0)-2.0,-mod(p.y-1.1,2.2)+1.1);\n    return degamma(texture2D(iChannel1,(p-vec2(-1.5,-1.0))*vec2(0.325,0.5)).rgb);\n}\n\nvec3 walls(vec3 p, vec3 n, vec3 wallColor){\n                \/\/MEH!\n            if(n.z>0.8 && p.z<0.0){ \/\/back wall\n                return sampleMovie(p.xy);\n            }else{\n            \t\/\/col=degamma(cubetex(iChannel2,0.5*p,nor).rgb);\n                return wallColor;\n            }\n}\n\nfloat random(float p){return fract(cos(p)*123456.);} \/\/[0,1]\n\nvec3 noise(vec2 uv){\n    return texture2D(iChannel0,uv).rgb;\n}\n\nvec3 noise2(vec2 uv, float r){\n    return texture2D(iChannel0,uv+0.1*vec2(cos(r),sin(r))).rgb;\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec2 ss = fragCoord.xy \/ iResolution.x;\n    \/\/stochastic aa\n    vec2 cs = (fragCoord.xy-iResolution.xy*0.5)\/iResolution.x; \/\/lower-left=-1,-y\/x\n    \n    float \/\/time=iGlobalTime*0.1;\n    time=0.4*cos(iGlobalTime*0.3);\n    \n    \n    \n    vec3 co;\n    vec3 ci;\n    if(iMouse.z>0.0){\n         time=2.0*(iMouse.x\/iResolution.x-0.5);\n        \n        float rotation=time;\n        co=rotY(vec3(0.0,0.0,5.0),rotation);\n    \tfloat zoom=0.5\/0.6;\n        ci=rotY(normalize(vec3(zoom*cs.x,zoom*cs.y,-1)),rotation);\n    }else{\n    \t\/\/time=0.0; \/\/STOP TIME!\n        float camz=3.0+8.0*(exp(smoothstep(5.0,30.0,iGlobalTime))-1.0);\n        float rotation=mix(time,-0.95,smoothstep(20.0,32.0,iGlobalTime));\n        co=rotY(vec3(0.0,0.0,camz),rotation)+vec3(1.2*mix(0.0,iGlobalTime-26.0,smoothstep(26.0,35.0,iGlobalTime)),0.0,0.0);\n    \tfloat zoom=0.5\/0.6;\n        ci=rotY(normalize(vec3(zoom*cs.x,zoom*cs.y,-1)),rotation);\n    }\n    \n    vec2 res=intersect(co,ci,0.0);\n    float t=res.r;\n    \n    vec3 col=vec3(0.0);\n    \n    if(t<50.0){\n        vec3 p=co+t*ci;\n        vec3 nor=calcNormal(p);\n        nor=normalize(nor);\n        vec2 uv=cubemap(p,nor);\n        \n        vec3 albedo=vec3(0.0);\n        vec3 emissive=vec3(0.0);\n        \n        if(res.g<0.9){\n            albedo=walls(p,nor,vec3(0.3));\n            emissive=walls(p,nor,vec3(0.0));\n\n        }else if(res.g<1.9){\n            albedo=vec3(0.2,0.2,0.2);\n        }\n        \n        \n        \n        float sampleScale=1.0\/16.0;\n        vec3 sum=vec3(0.0);\n        float iter=0.0;\n        \n        \n        for(int i=0;i<4;i++){\n            \/\/Choose a random direction along the normal.\n            \/\/First, random direction in hemisphere pointing up (this is very approximate, and wrong)\n            vec3 rd=vec3(random(iter*20.0),\n                         random(dot(p.xy,vec2(18.0,5.0))+iter*55.0),\n                         random( dot(p.xy,vec2(-7.0,8.0))+iter*81.0));\n            rd=2.0*(rd-vec3(0.5));\n            rd.z=abs(rd.z);\n            rd=normalize(texrot(rd,nor));\n            vec2 res2=intersectFast(p,rd,0.01,10.0);\n            vec3 p2=p+res2.r*rd;\n            vec3 nor2=normalize(calcNormal(p2));\n            if(res2.g<0.9){\n                sum+=dot(nor,rd)*walls(p2,nor2,vec3(0.0));\n            }\n            iter+=1.0;\n        }\n        \n        sum*=1.5; \/\/2015-11-05 modification; now uses 4 samples and is far granier, so this is just for aesthestics.\n        \/\/Might be possible to replace it with an analytical (mipmapped) approximation.\n\n        \n        float gloss=pow(clamp(2.0*cubetex(iChannel2,p.xzy*0.5,nor.xzy).b-0.5,0.0,1.0),0.3);\n        for(int i=0;i<4;i++){\n            vec3 rd=vec3(random(iter*20.0),\n                         random(dot(p.xy,vec2(18.0,5.0))+iter*55.0),\n                         random( dot(p.xy,vec2(-7.0,8.0))+iter*81.0));\n            rd=2.0*(rd-vec3(0.5));\n            rd.z=abs(rd.z);\n            rd=texrot(rd,nor);\n            \/\/do a hard mix\n            rd=normalize(mix(rd,reflect(ci,nor),gloss));\n            vec2 res2=intersectFast(p,rd,0.01,10.0);\n            vec3 p2=p+res2.r*rd;\n            vec3 nor2=normalize(calcNormal(p2));\n            if(res2.g<0.9){\n                sum+=gloss*walls(p2,nor2,vec3(0.0));\n            }\n            iter+=1.0;\n        }\n\n\n        \n        col=emissive+albedo*sum*sampleScale;\n    }\n    \n    \/\/fragColor=vec4(t\/20.0,t\/20.0,t\/20.0,1.0);\n    \/\/return;\n    \/\/Nope, not gamma correcting right now because it makes things look bad. Sorry.\n    \/\/Okay, I take that back. Maybe. TODO: perform actual radiosity test with real object\/camera\n\tfragColor = vec4(gamma(2.0*col),1.0);\n}","name":"Image","description":"","type":"image"}]}}